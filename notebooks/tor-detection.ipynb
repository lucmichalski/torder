{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This repo is to share the code shared during the TechGig webinar. \n",
    "#We have used a dataset taken from Canadian Institute of CyberSecurity. \n",
    "#We cannot share the data here; please contact a.habibi.l@unb.ca to obtain the dataset.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'SelectedFeatures-10s-TOR-NonTOR.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv\n",
    "dataframe = pd.read_csv(datapath,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data\n",
    "def dfNormalize(df):\n",
    "    for feature_name in df.columns:\n",
    "        df.loc[:,feature_name]= pd.to_numeric(df.loc[:,feature_name], errors='coerce').fillna(0)\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()   \n",
    "        if (max_value - min_value) > 0:\n",
    "            df.loc[:,feature_name] = (df.loc[:,feature_name] - min_value) / (max_value - min_value)\n",
    "        else:\n",
    "            df.loc[:,feature_name] = (df.loc[:,feature_name]- min_value)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67834, 29)\n",
      "        Source Port   Destination Port      Protocol   Flow Duration  \\\n",
      "count  67834.000000       67834.000000  67834.000000    6.783400e+04   \n",
      "mean   37912.753324       11566.395967     12.167291    2.991884e+06   \n",
      "std    20986.077326       18374.765123      5.459410    4.063005e+06   \n",
      "min       21.000000          21.000000      6.000000    0.000000e+00   \n",
      "25%    19305.000000         137.000000      6.000000    4.435975e+04   \n",
      "50%    43677.000000         443.000000     17.000000    4.108570e+05   \n",
      "75%    54685.000000       16311.000000     17.000000    7.325550e+06   \n",
      "max    65534.000000       65514.000000     17.000000    1.000000e+07   \n",
      "\n",
      "        Flow IAT Mean   Flow IAT Std   Flow IAT Max   Flow IAT Min  \\\n",
      "count    6.783400e+04   6.783400e+04   6.783400e+04   6.783400e+04   \n",
      "mean     3.155927e+05   2.209662e+05   8.983857e+05   1.924432e+05   \n",
      "std      6.988069e+05   6.409506e+05   1.738476e+06   5.780313e+05   \n",
      "min      0.000000e+00   0.000000e+00   0.000000e+00  -2.255000e+03   \n",
      "25%      9.951270e+03   0.000000e+00   2.892575e+04   2.600000e+01   \n",
      "50%      8.344079e+04   0.000000e+00   1.786225e+05   1.371500e+03   \n",
      "75%      4.106090e+05   5.790789e+04   4.641098e+05   2.075310e+05   \n",
      "max      9.987113e+06   7.045491e+06   9.998126e+06   9.987113e+06   \n",
      "\n",
      "       Fwd IAT Mean   Fwd IAT Std      ...        Bwd IAT Max   Bwd IAT Min  \\\n",
      "count  6.783400e+04  6.783400e+04      ...       6.783400e+04  6.783400e+04   \n",
      "mean   3.500551e+05  2.301546e+05      ...       4.760216e+05  5.158576e+04   \n",
      "std    8.391263e+05  6.798476e+05      ...       1.409648e+06  4.873526e+05   \n",
      "min    0.000000e+00  0.000000e+00      ...       0.000000e+00 -3.270000e+02   \n",
      "25%    0.000000e+00  0.000000e+00      ...       0.000000e+00  0.000000e+00   \n",
      "50%    1.996805e+04  0.000000e+00      ...       0.000000e+00  0.000000e+00   \n",
      "75%    4.112370e+05  3.034664e+04      ...       8.278800e+04  1.700000e+01   \n",
      "max    9.997140e+06  7.065086e+06      ...       9.996903e+06  9.996903e+06   \n",
      "\n",
      "        Active Mean   Active Std    Active Max    Active Min     Idle Mean  \\\n",
      "count  6.783400e+04      67834.0  6.783400e+04  6.783400e+04  6.783400e+04   \n",
      "mean   3.887655e+04          0.0  3.887655e+04  3.887655e+04  3.085054e+05   \n",
      "std    3.154634e+05          0.0  3.154634e+05  3.154634e+05  1.453953e+06   \n",
      "min    0.000000e+00          0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00          0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    0.000000e+00          0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    0.000000e+00          0.0  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    4.999893e+06          0.0  4.999893e+06  4.999893e+06  9.998126e+06   \n",
      "\n",
      "        Idle Std      Idle Max      Idle Min  \n",
      "count    67834.0  6.783400e+04  6.783400e+04  \n",
      "mean         0.0  3.085054e+05  3.085054e+05  \n",
      "std          0.0  1.453953e+06  1.453953e+06  \n",
      "min          0.0  0.000000e+00  0.000000e+00  \n",
      "25%          0.0  0.000000e+00  0.000000e+00  \n",
      "50%          0.0  0.000000e+00  0.000000e+00  \n",
      "75%          0.0  0.000000e+00  0.000000e+00  \n",
      "max          0.0  9.998126e+06  9.998126e+06  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "['Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Protocol', ' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Mean', ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Active Mean', ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Randomly permute the data\n",
    "print dataframe.shape\n",
    "dataframe = dataframe.reindex(np.random.permutation(dataframe.index)).copy()\n",
    "print(dataframe.describe())\n",
    "print (list(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Protocol   Flow Duration   Flow Bytes/s   Flow Packets/s  \\\n",
      "count  67834.000000    67834.000000   6.783400e+04     67834.000000   \n",
      "mean       0.560663        0.299188   4.225052e-04         0.001101   \n",
      "std        0.496310        0.406300   9.373635e-03         0.016519   \n",
      "min        0.000000        0.000000   0.000000e+00         0.000000   \n",
      "25%        0.000000        0.004436   1.744247e-07         0.000002   \n",
      "50%        1.000000        0.041086   2.218592e-06         0.000005   \n",
      "75%        1.000000        0.732555   3.613572e-05         0.000034   \n",
      "max        1.000000        1.000000   1.000000e+00         1.000000   \n",
      "\n",
      "        Flow IAT Mean   Flow IAT Std   Flow IAT Max   Flow IAT Min  \\\n",
      "count    67834.000000   67834.000000   67834.000000   67834.000000   \n",
      "mean         0.031600       0.031363       0.089855       0.019491   \n",
      "std          0.069971       0.090973       0.173880       0.057865   \n",
      "min          0.000000       0.000000       0.000000       0.000000   \n",
      "25%          0.000996       0.000000       0.002893       0.000228   \n",
      "50%          0.008355       0.000000       0.017866       0.000363   \n",
      "75%          0.041114       0.008219       0.046420       0.021001   \n",
      "max          1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "       Fwd IAT Mean   Fwd IAT Std      ...        Bwd IAT Max   Bwd IAT Min  \\\n",
      "count  67834.000000  67834.000000      ...       67834.000000  67834.000000   \n",
      "mean       0.035016      0.032576      ...           0.047617      0.005193   \n",
      "std        0.083937      0.096226      ...           0.141009      0.048749   \n",
      "min        0.000000      0.000000      ...           0.000000      0.000000   \n",
      "25%        0.000000      0.000000      ...           0.000000      0.000033   \n",
      "50%        0.001997      0.000000      ...           0.000000      0.000033   \n",
      "75%        0.041135      0.004295      ...           0.008281      0.000034   \n",
      "max        1.000000      1.000000      ...           1.000000      1.000000   \n",
      "\n",
      "        Active Mean   Active Std    Active Max    Active Min     Idle Mean  \\\n",
      "count  67834.000000      67834.0  67834.000000  67834.000000  67834.000000   \n",
      "mean       0.007775          0.0      0.007775      0.007775      0.030856   \n",
      "std        0.063094          0.0      0.063094      0.063094      0.145423   \n",
      "min        0.000000          0.0      0.000000      0.000000      0.000000   \n",
      "25%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
      "50%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
      "75%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
      "max        1.000000          0.0      1.000000      1.000000      1.000000   \n",
      "\n",
      "        Idle Std      Idle Max      Idle Min  \n",
      "count    67834.0  67834.000000  67834.000000  \n",
      "mean         0.0      0.030856      0.030856  \n",
      "std          0.0      0.145423      0.145423  \n",
      "min          0.0      0.000000      0.000000  \n",
      "25%          0.0      0.000000      0.000000  \n",
      "50%          0.0      0.000000      0.000000  \n",
      "75%          0.0      0.000000      0.000000  \n",
      "max          0.0      1.000000      1.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "keys = dataframe.keys()\n",
    "# Feature Selection, Dropping Source IP, Source Port, Destination IP and Destination Port as it \n",
    "# specific to each organisation network and generic model should not contain them. \n",
    "data_to_process = dataframe[keys[4:len(keys) - 1]].copy()\n",
    "#data_to_process = dataframe[[' Source Port',' Destination Port', ' Flow Duration', ' Flow Bytes/s', ' Flow Packets/s', ' Flow IAT Mean','Fwd IAT Mean','Bwd IAT Mean','Active Mean','Idle Mean','label']].copy()\n",
    "# do a data normalization\n",
    "x_normalised = dfNormalize(data_to_process)\n",
    "print(x_normalised.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the train and test data\n",
    "x_train = x_normalised.sample(frac=0.8, replace=True)\n",
    "x_test = x_normalised.drop(x_train.index)\n",
    "\n",
    "# change the labels and affix them\n",
    "change_labels = lambda x: 1 if x == 'nonTOR' else 0\n",
    "y_train = dataframe['label'].apply(change_labels).loc[x_train.index]\n",
    "y_test = dataframe['label'].apply(change_labels).loc[x_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "(6415, 24)\n"
     ]
    }
   ],
   "source": [
    "# Figure the Feature dimensions so that it can be used in Deep Neural Net later\n",
    "feature_dim = x_train.shape[1]\n",
    "print feature_dim\n",
    "print x_train[y_train==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to check the y_train\n",
    "#print y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "class 0 - NonTor       0.77      0.72      0.74      3609\n",
      "   class 1 - Tor       0.96      0.97      0.97     26857\n",
      "\n",
      "     avg / total       0.94      0.94      0.94     30466\n",
      "\n",
      "Accuracy = 94.04\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "lr=LogisticRegressionCV() \n",
    "lr.fit(x_train, y_train)\n",
    "y_predict = lr.predict(x_test)\n",
    "target_names = ['class 0 - NonTor', 'class 1 - Tor']\n",
    "print(classification_report(y_test, y_predict, target_names=target_names))\n",
    "print(\"Accuracy = {:.2f}\".format(lr.score(x_test, y_test.values)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               3200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 136,025\n",
      "Trainable params: 136,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Net Implementation using Keras and TensorFlow\n",
    "import tensorflow as tf\n",
    "sess= tf.Session()\n",
    "from keras import backend as K\n",
    "reload(K)\n",
    "K.set_session(sess)\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "hidden_layers = 10\n",
    "neurons_num = 128\n",
    "model = Sequential()\n",
    "model.add(Dense(feature_dim, input_dim= feature_dim, kernel_initializer='normal', activation='relu'))\n",
    "for _ in range(0, hidden_layers-1):\n",
    "    model.add(Dense(neurons_num, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48840 samples, validate on 5427 samples\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.1949 - acc: 0.9171 - val_loss: 0.1508 - val_acc: 0.9355\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.1439 - acc: 0.9410 - val_loss: 0.1371 - val_acc: 0.9403\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.1407 - acc: 0.9404 - val_loss: 0.1359 - val_acc: 0.9364\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.1373 - acc: 0.9430 - val_loss: 0.1322 - val_acc: 0.9432\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.1327 - acc: 0.9440 - val_loss: 0.1315 - val_acc: 0.9438\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.1322 - acc: 0.9456 - val_loss: 0.1282 - val_acc: 0.9475\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.1329 - acc: 0.9443 - val_loss: 0.1299 - val_acc: 0.9436\n",
      "Epoch 8/10\n",
      " - 3s - loss: 0.1284 - acc: 0.9462 - val_loss: 0.1321 - val_acc: 0.9444\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.1238 - acc: 0.9475 - val_loss: 0.1256 - val_acc: 0.9488\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.1182 - acc: 0.9482 - val_loss: 0.1161 - val_acc: 0.9495\n",
      "\n",
      "Test acc: 94.84%\n",
      "3609/3609 [==============================] - 0s 56us/step\n",
      "\n",
      "Test acc for class 0: 71.90%\n",
      "26857/26857 [==============================] - 1s 52us/step\n",
      "\n",
      "Test acc for class 1: 97.93%\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Net Implementation using Keras and TensorFlow\n",
    "# Compute the accuracies and visualise using TensorBoard\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit(x_train,y_train, epochs=10, batch_size=100, verbose=2, callbacks=[tensorboard],validation_split=0.1)\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "#loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"\\nTest %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "scores_0 = model.evaluate(x_test[y_test==0], y_test[y_test==0])\n",
    "print(\"\\nTest %s for class 0: %.2f%%\" % (model.metrics_names[1], scores_0[1]*100))\n",
    "scores_1 = model.evaluate(x_test[y_test==1], y_test[y_test==1])\n",
    "print(\"\\nTest %s for class 1: %.2f%%\" % (model.metrics_names[1], scores_1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good practice to clear Keras session\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
